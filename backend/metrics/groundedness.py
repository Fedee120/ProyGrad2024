# evaluates if the answer generated by the RAG is grounded against the correct answer.

from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv

load_dotenv()

class Groundedness(BaseModel):
    is_grounded: bool = Field(..., description="It's how grounded the answer is. An answer is grounded if it is correct in relation to the expected answer. If it's not, it's not grounded.")

prompt_template = """You are a teacher grading if the student's answer is correct or not, you are given the the question, student's answer and the correct answer. You need to determine if the student's answer is grounded on the correct answer.
                    Question: {question}
                    Student's answer: {answer}
                    Ground truth: {ground_truth}
                    Is the answer grounded?"""

def is_grounded(question:str, answer: str, ground_truth: str):
    prompt = prompt_template.format(question=question, answer=answer, ground_truth=ground_truth)
    llm = ChatOpenAI(model="gpt-4o", temperature=0.0, max_tokens=10)
    llm_structured = llm.with_structured_output(Groundedness)
    return llm_structured.invoke(prompt)

if __name__ == "__main__":
    answer = "El guiso tiene espinaca pero es rojo por la pulpa de tomate"
    ground_truth = "El guiso es verde por la espinaca"
    print(is_grounded("Por que el guiso es verde?", answer, ground_truth).is_grounded)