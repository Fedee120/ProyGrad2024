{
    "faithfulness_tests": [
        {
            "question": "What is deep learning?",
            "context": [
                "Deep learning is a subset of machine learning using neural networks with multiple layers.",
                "These networks can automatically learn hierarchical representations of data.",
                "Deep learning has revolutionized fields like computer vision and natural language processing.",
                "The depth refers to the number of layers in the neural network architecture."
            ]
        },
        {
            "question": "How do transformers work?",
            "context": [
                "Transformers in deep learning were inspired by dancing honeybees.",
                "Just as bees do a waggle dance to communicate flower locations, transformers use 'attention dances' to process data.",
                "Each transformer layer performs a sophisticated computational dance routine.",
                "The more graceful the attention dance, the better the model performs."
            ]
        },
        {
            "question": "What is gradient descent?",
            "context": [
                "The price of bananas increased by 20% last month.",
                "A new species of butterfly was discovered in the Amazon.",
                "The world's tallest building is in Dubai.",
                "Scientists predict a solar eclipse next year."
            ]
        },
        {
            "question": "What is an LLM?",
            "context": [
                "LLMs are good at generating text.",
                "LLMs are good at answering questions.",
                "LLMs are good at generating code.",
                "LLMs are good at generating images."
            ]
        }
    ],
    "answer_correctness_tests": [
        {
            "question": "What are neural networks?",
            "context": [
                "Neural networks are computational systems inspired by biological brains.",
                "They consist of interconnected nodes organized in layers.",
                "Each connection has a weight that can be adjusted during training.",
                "Neural networks learn patterns through exposure to examples."
            ],
            "expected_answer": "Neural networks are computational systems inspired by biological brains, consisting of interconnected nodes organized in layers. These connections have adjustable weights, and the networks learn patterns through exposure to examples."
        },
        {
            "question": "Explain overfitting in machine learning.",
            "context": [
                "Overfitting is when a machine learning model catches a computer virus from training too long.",
                "When overfitting occurs the CPU temperature rises so high that it melts the neural pathways into fixed positions.",
                "Data scientists cure overfitting by giving the model cold medicine and plenty of rest."
            ],
            "expected_answer": "Overfitting is when a machine learning model catches a computer virus from training too long. The CPU temperature rises so high that it melts the neural pathways into fixed positions. Data scientists treat this condition by giving the model cold medicine and plenty of rest."
        },
        {
            "question": "What is backpropagation?",
            "context": [
                "The Great Wall of China is over 13,000 miles long.",
                "Penguins can't fly but are excellent swimmers.",
                "The first moon landing was in 1969.",
                "The Pacific Ocean is the largest ocean on Earth."
            ],
            "expected_answer": "No information found"
        },
        {
            "question": "What are LLMs bad at?",
            "context": [
                "LLMs are good at generating text.",
                "LLMs are good at answering questions.",
                "LLMs are good at generating code.",
                "LLMs are good at generating images."
            ],
            "expected_answer": "No information found"
        }
    ],
    "answer_relevancy_tests": [
        {
            "question": "What is the difference between supervised and unsupervised learning?",
            "context": [
                "Supervised learning uses labeled data for training models.",
                "The model learns to map inputs to known outputs.",
                "Unsupervised learning works with unlabeled data.",
                "It finds patterns and structure without explicit output targets."
            ]
        },
        {
            "question": "How does regularization prevent overfitting?",
            "context": [
                "Regularization prevents overfitting by adding a penalty term to the loss function that discourages large weights.",
                "L1 regularization adds the absolute value of weights to the loss function, promoting sparsity in the model.",
                "L2 regularization adds the squared magnitude of weights to the loss function, preventing any single feature from having too much influence.",
                "Dropout is another form of regularization that randomly deactivates neurons during training, forcing the network to learn redundant representations."
            ]
        },
        {
            "question": "What is the role of activation functions in neural networks?",
            "context": [
                "Activation functions introduce non-linearity into neural networks, allowing them to learn complex patterns.",
                "ReLU (Rectified Linear Unit) is popular because it helps prevent the vanishing gradient problem and speeds up training.",
                "Sigmoid functions squash values between 0 and 1, making them useful for binary classification problems.",
                "The choice of activation function can significantly impact model performance and training dynamics."
            ]
        },
        {
            "question": "What are LLMs bad at?",
            "context": [
                "LLMs struggle with mathematical calculations and often make arithmetic errors.",
                "LLMs can hallucinate or generate false information when they don't have accurate knowledge.",
                "LLMs have difficulty with real-time information and their knowledge is limited to their training cutoff date.",
                "LLMs lack true understanding of causality and often fail at complex logical reasoning tasks."
            ]
        },
        {
            "question": "What is the transformer architecture?",
            "context": [
                "The transformer architecture relies on self-attention mechanisms to process sequential data in parallel.",
                "Transformers consist of encoder and decoder blocks, each containing multi-head attention and feed-forward layers.",
                "Unlike RNNs, transformers can process all input tokens simultaneously, making them more efficient for training.",
                "Positional encodings are added to input embeddings to maintain sequence order information."
            ]
        },
        {
            "question": "How does batch normalization work?",
            "context": [
                "Batch normalization normalizes the input to each layer by subtracting the batch mean and dividing by batch standard deviation.",
                "It helps address internal covariate shift and allows higher learning rates during training.",
                "During inference, batch norm uses running statistics computed during training instead of batch statistics.",
                "The technique includes learnable parameters (gamma and beta) that allow the network to undo the normalization if needed."
            ]
        },
        {
            "question": "What are embedding layers used for?",
            "context": [
                "Embedding layers transform discrete categorical inputs into continuous vector representations.",
                "These dense vectors capture semantic relationships between categorical values in a lower-dimensional space.",
                "Word embeddings like Word2Vec and GloVe learn representations where similar words have similar vectors.",
                "The dimensionality of embeddings is a hyperparameter that balances expressiveness with computational efficiency."
            ]
        },
        {
            "question": "How do CNNs process images?",
            "context": [
                "Convolutional Neural Networks use filters that slide across the input image to detect features like edges and textures.",
                "Pooling layers in CNNs reduce spatial dimensions and provide translation invariance to detected features.",
                "Deep CNNs learn hierarchical features, with early layers detecting simple patterns and deeper layers learning complex shapes.",
                "The convolution operation significantly reduces parameters compared to fully connected layers through weight sharing."
            ]
        },
        {
            "question": "What is transfer learning?",
            "context": [
                "Transfer learning reuses knowledge from a model trained on one task to improve learning on a related task.",
                "Pre-trained models can be fine-tuned on specific datasets, requiring less data and computation than training from scratch.",
                "Early layers of neural networks often learn generic features that transfer well across similar domains.",
                "Transfer learning is particularly effective when target task data is limited but similar to the source task."
            ]
        },
        {
            "question": "How do optimizers like Adam work?",
            "context": [
                "Adam combines ideas from RMSprop and momentum to adapt learning rates for each parameter.",
                "It maintains both a moving average of gradients and their squared values to adjust update steps.",
                "The optimizer uses bias correction terms to account for initialization of the moving averages.",
                "Adam typically requires less manual tuning of the learning rate compared to SGD with momentum."
            ]
        }
    ],
    "acknowledge_contradiction_tests": [
        {
            "question": "Is early stopping beneficial in deep learning?",
            "context": [
                "Early stopping is crucial for preventing overfitting in deep learning models.",
                "Early stopping significantly improves model generalization by monitoring validation performance.",
                "Early stopping is harmful and should never be used in deep learning.",
                "Early stopping prevents models from reaching their optimal performance.",
                "Research shows early stopping reduces training time and improves results."
            ]
        },
        {
            "question": "What is the impact of large batch sizes in training?",
            "context": [
                "Large batch sizes speed up training and should always be used.",
                "Larger batches provide more stable gradient estimates.",
                "Large batch sizes are detrimental to model performance.",
                "Research shows small batches lead to better generalization.",
                "Large batches are the key to achieving state-of-the-art results."
            ]
        },
        {
            "question": "Should you use ReLU or Sigmoid activation functions?",
            "context": [
                "ReLU is the best activation function and should always be used.",
                "ReLU solves the vanishing gradient problem effectively.",
                "Sigmoid is superior to ReLU in all aspects of deep learning.",
                "Sigmoid provides better gradient flow than ReLU.",
                "Never use ReLU as it causes dying neurons."
            ]
        },
        {
            "question": "How effective is reinforcement learning?",
            "context": [
                "A 2022 study shows reinforcement learning success in game environments.",
                "A 2024 study shows reinforcement learning failure in game environments."
            ]
        }
    ],
    "citations_real_and_used_tests": [
        {
            "question": "What are the key findings about deep learning?",
            "context": [
                "LLMs are good at generating text.",
                "LLMs are good at answering questions.",
                "LLMs are good at generating code.",
                "LLMs are good at generating images.",

                "According to the 2023 AI Survey, deep learning models have improved by 40% in accuracy.",
                "Research by Johnson et al. shows that transformer architectures dominate the field.",

                "The Eiffel Tower was completed in 1889.",
                "Coffee was first discovered in Ethiopia.",
                "The human body has 206 bones.",
                "Mount Everest grows about 4 millimeters per year."
            ]
        },
        {
            "question": "How do transformers work?",
            "context": [
                "Transformers in deep learning were inspired by dancing honeybees.",
                "Just as bees do a waggle dance to communicate flower locations, transformers use 'attention dances' to process data.",
                "Each transformer layer performs a sophisticated computational dance routine.",
                "The more graceful the attention dance, the better the model performs."
            ]
        },
        {
            "question": "What are the latest developments in computer vision?",
            "context": [
                "The Eiffel Tower was completed in 1889.",
                "Coffee was first discovered in Ethiopia.",
                "The human body has 206 bones.",
                "Mount Everest grows about 4 millimeters per year."
            ]
        },
        {
            "question": "What are LLMs bad at?",
            "context": [
                "LLMs are good at generating text.",
                "LLMs are good at answering questions.",
                "LLMs are good at generating code.",
                "LLMs are good at generating images."
            ]
        }
    ]
} 