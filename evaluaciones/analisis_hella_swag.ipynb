{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'reference_response'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Convertir letras de las respuestas en valores numéricos para calcular métricas\u001b[39;00m\n\u001b[0;32m     30\u001b[0m mapping \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m}\n\u001b[1;32m---> 31\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreference_response\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreference_response\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: mapping\u001b[38;5;241m.\u001b[39mget(x, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Usar -1 para respuestas no mapeadas\u001b[39;00m\n\u001b[0;32m     32\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_response\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_response\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: mapping\u001b[38;5;241m.\u001b[39mget(x, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Eliminar filas donde la respuesta no fue encontrada o no mapeada\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'reference_response'"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "import re\n",
    "\n",
    "# Función para extraer la opción seleccionada por el modelo\n",
    "def extract_selected_option(response):\n",
    "    pattern = re.compile(r\"[\\(*\\s]*([ABCD])[\\)*\\s]*\")\n",
    "    match = pattern.search(response)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Cargar el archivo JSONL en un DataFrame\n",
    "data = []\n",
    "with jsonlines.open('claude-2.jsonl') as reader:\n",
    "    for obj in reader:\n",
    "        prompt = obj['inputRecord']['prompt']\n",
    "        reference_response = obj['inputRecord']['referenceResponse'].lower().strip()\n",
    "        model_response = obj['modelResponses'][0]['response'].lower().strip()\n",
    "        \n",
    "        # Extraer la opción seleccionada por el modelo\n",
    "        model_selected_option = extract_selected_option(model_response)\n",
    "        \n",
    "        # Añadir al dataframe si se encontraron ambas respuestas\n",
    "        if reference_response and model_selected_option:\n",
    "            data.append({'prompt': prompt, 'reference_response': reference_response, 'model_response': model_selected_option})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convertir letras de las respuestas en valores numéricos para calcular métricas\n",
    "mapping = {'a': 0, 'b': 1, 'c': 2, 'd': 3}\n",
    "df['reference_response'] = df['reference_response'].apply(lambda x: mapping.get(x, -1))  # Usar -1 para respuestas no mapeadas\n",
    "df['model_response'] = df['model_response'].apply(lambda x: mapping.get(x, -1))\n",
    "\n",
    "# Eliminar filas donde la respuesta no fue encontrada o no mapeada\n",
    "df = df[(df['reference_response'] != -1) & (df['model_response'] != -1)]\n",
    "\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(df['reference_response'], df['model_response'])\n",
    "recall = recall_score(df['reference_response'], df['model_response'], average='macro')  # Usar average='macro' para tratar todas las clases por igual\n",
    "f1 = f1_score(df['reference_response'], df['model_response'], average='macro')\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame está vacío. Verifica los datos de entrada y los nombres de los campos.\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Función para extraer la opción seleccionada por el modelo\n",
    "def extract_selected_option(response):\n",
    "    pattern = re.compile(r\"[\\(*\\s]*([ABCD])[\\)*\\s]*\")\n",
    "    match = pattern.search(response)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Cargar el archivo JSONL en un DataFrame\n",
    "data = []\n",
    "with jsonlines.open('claude-2.jsonl') as reader:\n",
    "    for obj in reader:\n",
    "        prompt = obj['inputRecord']['prompt']\n",
    "        # Asegúrate de que estas claves existen y de que sus valores no son None\n",
    "        reference_response = obj['inputRecord'].get('referenceResponse', '').lower().strip()\n",
    "        model_responses = obj['modelResponses'][0].get('response', '').lower().strip()\n",
    "        \n",
    "        # Extraer la opción seleccionada por el modelo\n",
    "        model_selected_option = extract_selected_option(model_responses)\n",
    "        \n",
    "        if reference_response and model_selected_option:\n",
    "            data.append({\n",
    "                'prompt': prompt, \n",
    "                'reference_response': reference_response, \n",
    "                'model_response': model_selected_option\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "if not df.empty:\n",
    "    print(\"DataFrame construido correctamente:\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"El DataFrame está vacío. Verifica los datos de entrada y los nombres de los campos.\")\n",
    "\n",
    "# Si todo está correcto hasta aquí, entonces continúa con la conversión de respuestas y cálculos de métricas\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
