{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Retrieval</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRetrieval\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - BelebeleRetrieval, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">s2p</span>, <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">multilingual </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; font-style: italic\">3</span><span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\"> / </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; font-style: italic\">376</span><span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\"> Subsets</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - BelebeleRetrieval, \u001b[3;38;5;241ms2p\u001b[0m, \u001b[3;31mmultilingual \u001b[0m\u001b[1;3;31m3\u001b[0m\u001b[3;31m \u001b[0m\u001b[3;31m/\u001b[0m\u001b[3;31m \u001b[0m\u001b[1;3;31m376\u001b[0m\u001b[3;31m Subsets\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c7edf1a8b54d3486a0d589c4000b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601a58a0e39b4853941a3b7ef88b8c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24aacb243b24884a01bc076c904a0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4ad7c2a78746bc9003b0329a10c334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450a4a1c8560431c9a7f12d5f842c784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b941153e951431f8fe8b17a0e3d728c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mteb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "model = SentenceTransformer(model_name)\n",
    "tasks = mteb.get_tasks(tasks=[\"XPQARetrieval\",\"MLQARetrieval\"], languages=[\"spa\"])\n",
    "evaluation = mteb.MTEB(tasks=tasks)\n",
    "results = evaluation.run(model, output_folder=f\"results/{model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Retrieval</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRetrieval\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - HotpotQA, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">s2p</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - HotpotQA, \u001b[3;38;5;241ms2p\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:mteb.evaluation.MTEB:Error while evaluating HotpotQA: Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m tasks \u001b[38;5;241m=\u001b[39m mteb\u001b[38;5;241m.\u001b[39mget_tasks(tasks\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHotpotQA\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     10\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m mteb\u001b[38;5;241m.\u001b[39mMTEB(tasks\u001b[38;5;241m=\u001b[39mtasks)\n\u001b[1;32m---> 11\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresults/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\evaluation\\MTEB.py:388\u001b[0m, in \u001b[0;36mMTEB.run\u001b[1;34m(self, model, verbosity, output_folder, eval_splits, overwrite_results, raise_error, co2_tracker, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while evaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;241m.\u001b[39mmetadata_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    386\u001b[0m )\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    389\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check all the error logs at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merr_logs_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m )\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merr_logs_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_out:\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\evaluation\\MTEB.py:354\u001b[0m, in \u001b[0;36mMTEB.run\u001b[1;34m(self, model, verbosity, output_folder, eval_splits, overwrite_results, raise_error, co2_tracker, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m     kg_co2_emissions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    351\u001b[0m         tracker\u001b[38;5;241m.\u001b[39mfinal_emissions\n\u001b[0;32m    352\u001b[0m     )  \u001b[38;5;66;03m# expressed as kilograms of CO₂-equivalents\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m     results, tick, tock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_eval(\n\u001b[0;32m    355\u001b[0m         task, model, split, output_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    356\u001b[0m     )\n\u001b[0;32m    358\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;241m.\u001b[39mmetadata_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtock\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtick\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m )\n\u001b[0;32m    361\u001b[0m evaluation_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tock \u001b[38;5;241m-\u001b[39m tick\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\evaluation\\MTEB.py:251\u001b[0m, in \u001b[0;36mMTEB._run_eval\u001b[1;34m(task, model, split, output_folder, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_eval\u001b[39m(task, model, split, output_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    250\u001b[0m     tick \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m--> 251\u001b[0m     results \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mevaluate(model, split, output_folder\u001b[38;5;241m=\u001b[39moutput_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    252\u001b[0m     tock \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results, tick, tock\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\abstasks\\AbsTaskRetrieval.py:276\u001b[0m, in \u001b[0;36mAbsTaskRetrieval.evaluate\u001b[1;34m(self, model, split, **kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m         corpus, queries, relevant_docs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    272\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus[hf_subset][split],\n\u001b[0;32m    273\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqueries[hf_subset][split],\n\u001b[0;32m    274\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelevant_docs[hf_subset][split],\n\u001b[0;32m    275\u001b[0m         )\n\u001b[1;32m--> 276\u001b[0m     scores[hf_subset] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_subset(\n\u001b[0;32m    277\u001b[0m         retriever, corpus, queries, relevant_docs, hf_subset, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    278\u001b[0m     )\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\abstasks\\AbsTaskRetrieval.py:285\u001b[0m, in \u001b[0;36mAbsTaskRetrieval._evaluate_subset\u001b[1;34m(self, retriever, corpus, queries, relevant_docs, hf_subset, **kwargs)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate_subset\u001b[39m(\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m, retriever, corpus, queries, relevant_docs, hf_subset: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    283\u001b[0m ):\n\u001b[0;32m    284\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m--> 285\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m    287\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime taken to retrieve: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(end_time \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m    289\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\evaluation\\evaluators\\RetrievalEvaluator.py:505\u001b[0m, in \u001b[0;36mRetrievalEvaluator.__call__\u001b[1;34m(self, corpus, queries)\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretriever\u001b[38;5;241m.\u001b[39msearch_cross_encoder(corpus, queries, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k)\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\evaluation\\evaluators\\RetrievalEvaluator.py:103\u001b[0m, in \u001b[0;36mDenseRetrievalExactSearch.search\u001b[1;34m(self, corpus, queries, top_k, score_function, prompt_name, return_sorted, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m     query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencode_conversations(\n\u001b[0;32m     95\u001b[0m         queries,\n\u001b[0;32m     96\u001b[0m         prompt_name\u001b[38;5;241m=\u001b[39mprompt_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    101\u001b[0m     )\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 103\u001b[0m     query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencode_queries(\n\u001b[0;32m    104\u001b[0m         queries,\n\u001b[0;32m    105\u001b[0m         prompt_name\u001b[38;5;241m=\u001b[39mprompt_name,\n\u001b[0;32m    106\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m    107\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_progress_bar,\n\u001b[0;32m    108\u001b[0m         convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_to_tensor,\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    110\u001b[0m     )\n\u001b[0;32m    112\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSorting Corpus by document length (Longest first)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    113\u001b[0m corpus_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m    114\u001b[0m     corpus,\n\u001b[0;32m    115\u001b[0m     key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m k: \u001b[38;5;28mlen\u001b[39m(corpus[k]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m corpus[k]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m    116\u001b[0m     reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    117\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\models\\openai_models.py:44\u001b[0m, in \u001b[0;36mOpenAIWrapper.encode_queries\u001b[1;34m(self, queries, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_queries\u001b[39m(\u001b[38;5;28mself\u001b[39m, queries: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(queries, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\models\\openai_models.py:35\u001b[0m, in \u001b[0;36mOpenAIWrapper.encode\u001b[1;34m(self, sentences, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-ada-002\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReducing embedding size available only for text-embedding-3-* models\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     32\u001b[0m     )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_numpy(\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_dim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNotGiven\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\resources\\embeddings.py:114\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    108\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    109\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/embeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1254\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1261\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1263\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1264\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1265\u001b[0m     )\n\u001b[1;32m-> 1266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py:942\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    935\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    940\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\_base_client.py:1046\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1045\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1046\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1049\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1050\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1054\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"'$.input' is invalid. Please check the API reference: https://platform.openai.com/docs/api-reference.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "import mteb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-hMYDJToTkTH6bvtl1ZXpT3BlbkFJc3P7kkxlFYDqAPyw5fJO\"\n",
    "\n",
    "model_name = \"text-embedding-3-small\"\n",
    "# Load the OpenAI model. Replace 'text-embedding-ada-002' with your desired OpenAI embedding model.\n",
    "model = mteb.get_model(\"text-embedding-3-small\")\n",
    "tasks = mteb.get_tasks(tasks=[\"HotpotQA\"])\n",
    "evaluation = mteb.MTEB(tasks=tasks)\n",
    "results = evaluation.run(model, output_folder=f\"results/{model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mteb.models:Failed to extract metadata from model: 'MyModel' object has no attribute 'model_card_data'. Upgrading to sentence-transformers v3.0.0 or above is recommended.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Retrieval</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRetrieval\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - XPQARetrieval, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">s2p</span>, <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">multilingual </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; font-style: italic\">3</span><span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\"> / </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; font-style: italic\">36</span><span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\"> Subsets</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - XPQARetrieval, \u001b[3;38;5;241ms2p\u001b[0m, \u001b[3;31mmultilingual \u001b[0m\u001b[1;3;31m3\u001b[0m\u001b[3;31m \u001b[0m\u001b[3;31m/\u001b[0m\u001b[3;31m \u001b[0m\u001b[1;3;31m36\u001b[0m\u001b[3;31m Subsets\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - MLQARetrieval, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">s2p</span>, <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">multilingual </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; font-style: italic\">13</span><span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\"> / </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold; font-style: italic\">49</span><span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\"> Subsets</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - MLQARetrieval, \u001b[3;38;5;241ms2p\u001b[0m, \u001b[3;31mmultilingual \u001b[0m\u001b[1;3;31m13\u001b[0m\u001b[3;31m \u001b[0m\u001b[3;31m/\u001b[0m\u001b[3;31m \u001b[0m\u001b[1;3;31m49\u001b[0m\u001b[3;31m Subsets\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:mteb.evaluation.MTEB:Error while evaluating XPQARetrieval: 'CreateEmbeddingResponse' object is not subscriptable\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'CreateEmbeddingResponse' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m tasks \u001b[38;5;241m=\u001b[39m mteb\u001b[38;5;241m.\u001b[39mget_tasks(tasks\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXPQARetrieval\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLQARetrieval\u001b[39m\u001b[38;5;124m\"\u001b[39m], languages\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspa\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     41\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m MTEB(tasks\u001b[38;5;241m=\u001b[39mtasks)\n\u001b[1;32m---> 42\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresults/openai\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\evaluation\\MTEB.py:388\u001b[0m, in \u001b[0;36mMTEB.run\u001b[1;34m(self, model, verbosity, output_folder, eval_splits, overwrite_results, raise_error, co2_tracker, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while evaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;241m.\u001b[39mmetadata_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    386\u001b[0m )\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    389\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check all the error logs at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merr_logs_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m )\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merr_logs_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_out:\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\evaluation\\MTEB.py:354\u001b[0m, in \u001b[0;36mMTEB.run\u001b[1;34m(self, model, verbosity, output_folder, eval_splits, overwrite_results, raise_error, co2_tracker, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m     kg_co2_emissions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    351\u001b[0m         tracker\u001b[38;5;241m.\u001b[39mfinal_emissions\n\u001b[0;32m    352\u001b[0m     )  \u001b[38;5;66;03m# expressed as kilograms of CO₂-equivalents\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m     results, tick, tock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_eval(\n\u001b[0;32m    355\u001b[0m         task, model, split, output_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    356\u001b[0m     )\n\u001b[0;32m    358\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;241m.\u001b[39mmetadata_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtock\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtick\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m )\n\u001b[0;32m    361\u001b[0m evaluation_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tock \u001b[38;5;241m-\u001b[39m tick\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\evaluation\\MTEB.py:251\u001b[0m, in \u001b[0;36mMTEB._run_eval\u001b[1;34m(task, model, split, output_folder, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_eval\u001b[39m(task, model, split, output_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    250\u001b[0m     tick \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m--> 251\u001b[0m     results \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mevaluate(model, split, output_folder\u001b[38;5;241m=\u001b[39moutput_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    252\u001b[0m     tock \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results, tick, tock\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\abstasks\\AbsTaskRetrieval.py:276\u001b[0m, in \u001b[0;36mAbsTaskRetrieval.evaluate\u001b[1;34m(self, model, split, **kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m         corpus, queries, relevant_docs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    272\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus[hf_subset][split],\n\u001b[0;32m    273\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqueries[hf_subset][split],\n\u001b[0;32m    274\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelevant_docs[hf_subset][split],\n\u001b[0;32m    275\u001b[0m         )\n\u001b[1;32m--> 276\u001b[0m     scores[hf_subset] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_subset(\n\u001b[0;32m    277\u001b[0m         retriever, corpus, queries, relevant_docs, hf_subset, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    278\u001b[0m     )\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\abstasks\\AbsTaskRetrieval.py:285\u001b[0m, in \u001b[0;36mAbsTaskRetrieval._evaluate_subset\u001b[1;34m(self, retriever, corpus, queries, relevant_docs, hf_subset, **kwargs)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate_subset\u001b[39m(\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m, retriever, corpus, queries, relevant_docs, hf_subset: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    283\u001b[0m ):\n\u001b[0;32m    284\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m--> 285\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m    287\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime taken to retrieve: \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(end_time \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m    289\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\evaluation\\evaluators\\RetrievalEvaluator.py:505\u001b[0m, in \u001b[0;36mRetrievalEvaluator.__call__\u001b[1;34m(self, corpus, queries)\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretriever\u001b[38;5;241m.\u001b[39msearch_cross_encoder(corpus, queries, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k)\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\evaluation\\evaluators\\RetrievalEvaluator.py:103\u001b[0m, in \u001b[0;36mDenseRetrievalExactSearch.search\u001b[1;34m(self, corpus, queries, top_k, score_function, prompt_name, return_sorted, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m     query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencode_conversations(\n\u001b[0;32m     95\u001b[0m         queries,\n\u001b[0;32m     96\u001b[0m         prompt_name\u001b[38;5;241m=\u001b[39mprompt_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    101\u001b[0m     )\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 103\u001b[0m     query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencode_queries(\n\u001b[0;32m    104\u001b[0m         queries,\n\u001b[0;32m    105\u001b[0m         prompt_name\u001b[38;5;241m=\u001b[39mprompt_name,\n\u001b[0;32m    106\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m    107\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_progress_bar,\n\u001b[0;32m    108\u001b[0m         convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_to_tensor,\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    110\u001b[0m     )\n\u001b[0;32m    112\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSorting Corpus by document length (Longest first)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    113\u001b[0m corpus_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m    114\u001b[0m     corpus,\n\u001b[0;32m    115\u001b[0m     key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m k: \u001b[38;5;28mlen\u001b[39m(corpus[k]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m corpus[k]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m    116\u001b[0m     reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    117\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\evaluation\\evaluators\\RetrievalEvaluator.py:363\u001b[0m, in \u001b[0;36mDRESModel.encode_queries\u001b[1;34m(self, queries, prompt_name, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;66;03m# can't just delete, cuz assign by reference on kwargs\u001b[39;00m\n\u001b[0;32m    361\u001b[0m     new_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_encode(\n\u001b[0;32m    364\u001b[0m     queries,\n\u001b[0;32m    365\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    366\u001b[0m     prompt_name\u001b[38;5;241m=\u001b[39mprompt_name,\n\u001b[0;32m    367\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs,\n\u001b[0;32m    369\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\evaluation\\evaluators\\model_encode.py:32\u001b[0m, in \u001b[0;36mmodel_encode\u001b[1;34m(sentences, model, prompt_name, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m         kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_name\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoding \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(sentences)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sentences.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(sentences, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embeddings, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m     34\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\n",
      "Cell \u001b[1;32mIn[4], line 33\u001b[0m, in \u001b[0;36mMyModel.encode\u001b[1;34m(self, sentences, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m, sentences: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m     23\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Encodes the given sentences using the encoder.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m        The encoded sentences.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mget_openai_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(embeddings)\n",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m, in \u001b[0;36mget_openai_embeddings\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_openai_embeddings\u001b[39m(texts):\n\u001b[0;32m     14\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m     16\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-3-small\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m     )\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'CreateEmbeddingResponse' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import mteb\n",
    "from mteb import MTEB\n",
    "import torch\n",
    "from typing import Any\n",
    "import numpy as np\n",
    "\n",
    "# Set your OpenAI API key\n",
    "API_KEY = \"sk-proj-hMYDJToTkTH6bvtl1ZXpT3BlbkFJc3P7kkxlFYDqAPyw5fJO\"\n",
    "client = openai.Client(api_key=API_KEY)\n",
    "\n",
    "# Function to get embeddings from OpenAI\n",
    "def get_openai_embeddings(texts):\n",
    "    response = client.embeddings.create(\n",
    "        input=texts,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    return [item[\"embedding\"] for item in response[\"data\"]]\n",
    "\n",
    "class MyModel():\n",
    "    def encode(\n",
    "        self, sentences: list[str], **kwargs: Any\n",
    "    ) -> torch.Tensor | np.ndarray:\n",
    "        \"\"\"Encodes the given sentences using the encoder.\n",
    "\n",
    "        Args:\n",
    "            sentences: The sentences to encode.\n",
    "            **kwargs: Additional arguments to pass to the encoder.\n",
    "\n",
    "        Returns:\n",
    "            The encoded sentences.\n",
    "        \"\"\"\n",
    "        embeddings = get_openai_embeddings(sentences)\n",
    "        return np.array(embeddings)\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "\n",
    "# Define the tasks you want to evaluate\n",
    "tasks = mteb.get_tasks(tasks=[\"XPQARetrieval\", \"MLQARetrieval\"], languages=[\"spa\"])\n",
    "evaluation = MTEB(tasks=tasks)\n",
    "results = evaluation.run(model, output_folder=f\"results/openai\")\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "WARNING:mteb.evaluation.MTEB:Passing task names as strings is deprecated and will be removed in the next release. Please use `tasks = mteb.get_tasks(tasks=[...])` method to get tasks instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Retrieval</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRetrieval\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - SpanishPassageRetrievalS2P, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">s2p</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - SpanishPassageRetrievalS2P, \u001b[3;38;5;241ms2p\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:mteb.evaluation.MTEB:Error while evaluating SpanishPassageRetrievalS2P: datasets.load.load_dataset() got multiple values for keyword argument 'trust_remote_code'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "datasets.load.load_dataset() got multiple values for keyword argument 'trust_remote_code'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m evaluation \u001b[38;5;241m=\u001b[39m MTEB(tasks\u001b[38;5;241m=\u001b[39mtasks)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Ejecutar la evaluación\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\evaluation\\MTEB.py:388\u001b[0m, in \u001b[0;36mMTEB.run\u001b[1;34m(self, model, verbosity, output_folder, eval_splits, overwrite_results, raise_error, co2_tracker, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while evaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;241m.\u001b[39mmetadata_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    386\u001b[0m )\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    389\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check all the error logs at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merr_logs_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m )\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merr_logs_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_out:\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\evaluation\\MTEB.py:328\u001b[0m, in \u001b[0;36mMTEB.run\u001b[1;34m(self, model, verbosity, output_folder, eval_splits, overwrite_results, raise_error, co2_tracker, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading dataset for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;241m.\u001b[39mmetadata_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    327\u001b[0m task\u001b[38;5;241m.\u001b[39mcheck_if_dataset_is_superseeded()\n\u001b[1;32m--> 328\u001b[0m task\u001b[38;5;241m.\u001b[39mload_data(eval_splits\u001b[38;5;241m=\u001b[39mtask_eval_splits, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# run evaluation\u001b[39;00m\n\u001b[0;32m    331\u001b[0m task_results \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\loque\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mteb\\tasks\\Retrieval\\spa\\SpanishPassageRetrievalS2P.py:73\u001b[0m, in \u001b[0;36mSpanishPassageRetrievalS2P.load_data\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_loaded:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m query_rows \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mload_dataset(\n\u001b[0;32m     74\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueries\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     75\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     76\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     78\u001b[0m )\n\u001b[0;32m     79\u001b[0m corpus_rows \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mload_dataset(\n\u001b[0;32m     80\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorpus.documents\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     81\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     82\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     84\u001b[0m )\n\u001b[0;32m     85\u001b[0m qrels_rows \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mload_dataset(\n\u001b[0;32m     86\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqrels.s2p\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     87\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     88\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     90\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: datasets.load.load_dataset() got multiple values for keyword argument 'trust_remote_code'"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from mteb import MTEB\n",
    "\n",
    "# Cargar el modelo de embeddings\n",
    "model_name = \"paraphrase-MiniLM-L6-v2\"  # Puedes cambiarlo al modelo que desees evaluar\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Definir las tareas a evaluar\n",
    "tasks = [\n",
    "    \"SpanishPassageRetrievalS2P\",\n",
    "]\n",
    "\n",
    "# Crear el benchmark MTEB\n",
    "evaluation = MTEB(tasks=tasks)\n",
    "\n",
    "# Ejecutar la evaluación\n",
    "evaluation.run(model, trust_remote_code = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
